{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.809347465202401,
  "eval_steps": 500,
  "global_step": 22000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012769761205465458,
      "grad_norm": 0.04110852628946304,
      "learning_rate": 4.978929894010982e-05,
      "loss": 0.2287,
      "step": 100
    },
    {
      "epoch": 0.025539522410930916,
      "grad_norm": 0.009646755643188953,
      "learning_rate": 4.9576469586685395e-05,
      "loss": 0.1028,
      "step": 200
    },
    {
      "epoch": 0.03830928361639637,
      "grad_norm": 0.08403908461332321,
      "learning_rate": 4.9363640233260973e-05,
      "loss": 0.1848,
      "step": 300
    },
    {
      "epoch": 0.05107904482186183,
      "grad_norm": 0.026804575696587563,
      "learning_rate": 4.915081087983655e-05,
      "loss": 0.1013,
      "step": 400
    },
    {
      "epoch": 0.06384880602732729,
      "grad_norm": 57.64906311035156,
      "learning_rate": 4.8937981526412125e-05,
      "loss": 0.0754,
      "step": 500
    },
    {
      "epoch": 0.07661856723279274,
      "grad_norm": 53.69635009765625,
      "learning_rate": 4.87251521729877e-05,
      "loss": 0.1631,
      "step": 600
    },
    {
      "epoch": 0.08938832843825821,
      "grad_norm": 0.014839285984635353,
      "learning_rate": 4.8512322819563276e-05,
      "loss": 0.0697,
      "step": 700
    },
    {
      "epoch": 0.10215808964372367,
      "grad_norm": 29.32345199584961,
      "learning_rate": 4.829949346613885e-05,
      "loss": 0.0901,
      "step": 800
    },
    {
      "epoch": 0.11492785084918912,
      "grad_norm": 0.0040067099034786224,
      "learning_rate": 4.8086664112714433e-05,
      "loss": 0.0444,
      "step": 900
    },
    {
      "epoch": 0.12769761205465457,
      "grad_norm": 0.010969611816108227,
      "learning_rate": 4.7873834759290006e-05,
      "loss": 0.0835,
      "step": 1000
    },
    {
      "epoch": 0.14046737326012004,
      "grad_norm": 0.005487270187586546,
      "learning_rate": 4.766100540586558e-05,
      "loss": 0.0481,
      "step": 1100
    },
    {
      "epoch": 0.15323713446558548,
      "grad_norm": 0.0030679006595164537,
      "learning_rate": 4.744817605244116e-05,
      "loss": 0.0071,
      "step": 1200
    },
    {
      "epoch": 0.16600689567105095,
      "grad_norm": 0.005190088413655758,
      "learning_rate": 4.723534669901673e-05,
      "loss": 0.0535,
      "step": 1300
    },
    {
      "epoch": 0.17877665687651642,
      "grad_norm": 0.007095638662576675,
      "learning_rate": 4.70225173455923e-05,
      "loss": 0.0265,
      "step": 1400
    },
    {
      "epoch": 0.19154641808198186,
      "grad_norm": 0.012279519811272621,
      "learning_rate": 4.680968799216788e-05,
      "loss": 0.0854,
      "step": 1500
    },
    {
      "epoch": 0.20431617928744733,
      "grad_norm": 0.005554014351218939,
      "learning_rate": 4.659685863874346e-05,
      "loss": 0.0387,
      "step": 1600
    },
    {
      "epoch": 0.21708594049291277,
      "grad_norm": 0.0024566776119172573,
      "learning_rate": 4.638402928531904e-05,
      "loss": 0.022,
      "step": 1700
    },
    {
      "epoch": 0.22985570169837824,
      "grad_norm": 0.003912836778908968,
      "learning_rate": 4.617119993189461e-05,
      "loss": 0.0467,
      "step": 1800
    },
    {
      "epoch": 0.2426254629038437,
      "grad_norm": 0.012654701247811317,
      "learning_rate": 4.595837057847018e-05,
      "loss": 0.0264,
      "step": 1900
    },
    {
      "epoch": 0.25539522410930915,
      "grad_norm": 0.0020011672750115395,
      "learning_rate": 4.574554122504576e-05,
      "loss": 0.0183,
      "step": 2000
    },
    {
      "epoch": 0.2681649853147746,
      "grad_norm": 0.010527186095714569,
      "learning_rate": 4.553271187162133e-05,
      "loss": 0.0505,
      "step": 2100
    },
    {
      "epoch": 0.2809347465202401,
      "grad_norm": 8.955072402954102,
      "learning_rate": 4.531988251819691e-05,
      "loss": 0.0727,
      "step": 2200
    },
    {
      "epoch": 0.29370450772570555,
      "grad_norm": 12.210529327392578,
      "learning_rate": 4.510705316477249e-05,
      "loss": 0.0646,
      "step": 2300
    },
    {
      "epoch": 0.30647426893117097,
      "grad_norm": 0.012646235525608063,
      "learning_rate": 4.489422381134806e-05,
      "loss": 0.0715,
      "step": 2400
    },
    {
      "epoch": 0.31924403013663644,
      "grad_norm": 0.003168779890984297,
      "learning_rate": 4.4681394457923635e-05,
      "loss": 0.0004,
      "step": 2500
    },
    {
      "epoch": 0.3320137913421019,
      "grad_norm": 0.007901891134679317,
      "learning_rate": 4.4468565104499214e-05,
      "loss": 0.0396,
      "step": 2600
    },
    {
      "epoch": 0.3447835525475674,
      "grad_norm": 0.014508792199194431,
      "learning_rate": 4.4255735751074786e-05,
      "loss": 0.0244,
      "step": 2700
    },
    {
      "epoch": 0.35755331375303284,
      "grad_norm": 0.004278990440070629,
      "learning_rate": 4.4042906397650365e-05,
      "loss": 0.0002,
      "step": 2800
    },
    {
      "epoch": 0.37032307495849826,
      "grad_norm": 19.546052932739258,
      "learning_rate": 4.3830077044225944e-05,
      "loss": 0.0229,
      "step": 2900
    },
    {
      "epoch": 0.3830928361639637,
      "grad_norm": 0.038650788366794586,
      "learning_rate": 4.3617247690801517e-05,
      "loss": 0.0734,
      "step": 3000
    },
    {
      "epoch": 0.3958625973694292,
      "grad_norm": 0.04419146850705147,
      "learning_rate": 4.3404418337377095e-05,
      "loss": 0.0439,
      "step": 3100
    },
    {
      "epoch": 0.40863235857489466,
      "grad_norm": 0.0030529533978551626,
      "learning_rate": 4.319158898395267e-05,
      "loss": 0.0553,
      "step": 3200
    },
    {
      "epoch": 0.42140211978036013,
      "grad_norm": 0.0028051354456692934,
      "learning_rate": 4.297875963052824e-05,
      "loss": 0.0148,
      "step": 3300
    },
    {
      "epoch": 0.43417188098582554,
      "grad_norm": 0.007198524661362171,
      "learning_rate": 4.276593027710382e-05,
      "loss": 0.0568,
      "step": 3400
    },
    {
      "epoch": 0.446941642191291,
      "grad_norm": 0.0031410036608576775,
      "learning_rate": 4.25531009236794e-05,
      "loss": 0.0424,
      "step": 3500
    },
    {
      "epoch": 0.4597114033967565,
      "grad_norm": 0.0032107660081237555,
      "learning_rate": 4.234027157025497e-05,
      "loss": 0.0003,
      "step": 3600
    },
    {
      "epoch": 0.47248116460222195,
      "grad_norm": 0.0024295125622302294,
      "learning_rate": 4.212744221683055e-05,
      "loss": 0.0622,
      "step": 3700
    },
    {
      "epoch": 0.4852509258076874,
      "grad_norm": 0.001044046483002603,
      "learning_rate": 4.191461286340612e-05,
      "loss": 0.0002,
      "step": 3800
    },
    {
      "epoch": 0.49802068701315283,
      "grad_norm": 0.18116824328899384,
      "learning_rate": 4.17017835099817e-05,
      "loss": 0.0758,
      "step": 3900
    },
    {
      "epoch": 0.5107904482186183,
      "grad_norm": 0.01235539373010397,
      "learning_rate": 4.148895415655727e-05,
      "loss": 0.0515,
      "step": 4000
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 0.00931901577860117,
      "learning_rate": 4.127612480313285e-05,
      "loss": 0.0205,
      "step": 4100
    },
    {
      "epoch": 0.5363299706295492,
      "grad_norm": 0.030415989458560944,
      "learning_rate": 4.106329544970843e-05,
      "loss": 0.0876,
      "step": 4200
    },
    {
      "epoch": 0.5490997318350147,
      "grad_norm": 0.007237534038722515,
      "learning_rate": 4.0850466096284e-05,
      "loss": 0.0113,
      "step": 4300
    },
    {
      "epoch": 0.5618694930404802,
      "grad_norm": 0.0058343904092907906,
      "learning_rate": 4.0637636742859574e-05,
      "loss": 0.0206,
      "step": 4400
    },
    {
      "epoch": 0.5746392542459456,
      "grad_norm": 0.07916966080665588,
      "learning_rate": 4.042480738943515e-05,
      "loss": 0.0751,
      "step": 4500
    },
    {
      "epoch": 0.5874090154514111,
      "grad_norm": 0.0018266955157741904,
      "learning_rate": 4.0211978036010725e-05,
      "loss": 0.0171,
      "step": 4600
    },
    {
      "epoch": 0.6001787766568765,
      "grad_norm": 0.001194251817651093,
      "learning_rate": 3.9999148682586304e-05,
      "loss": 0.0002,
      "step": 4700
    },
    {
      "epoch": 0.6129485378623419,
      "grad_norm": 0.0024220033083111048,
      "learning_rate": 3.978631932916188e-05,
      "loss": 0.0537,
      "step": 4800
    },
    {
      "epoch": 0.6257182990678074,
      "grad_norm": 0.002136227209120989,
      "learning_rate": 3.9573489975737455e-05,
      "loss": 0.0184,
      "step": 4900
    },
    {
      "epoch": 0.6384880602732729,
      "grad_norm": 0.0016456623561680317,
      "learning_rate": 3.9360660622313034e-05,
      "loss": 0.0483,
      "step": 5000
    },
    {
      "epoch": 0.6512578214787383,
      "grad_norm": 0.006170753855258226,
      "learning_rate": 3.9147831268888606e-05,
      "loss": 0.0625,
      "step": 5100
    },
    {
      "epoch": 0.6640275826842038,
      "grad_norm": 0.035519275814294815,
      "learning_rate": 3.893500191546418e-05,
      "loss": 0.0436,
      "step": 5200
    },
    {
      "epoch": 0.6767973438896693,
      "grad_norm": 0.0015102177858352661,
      "learning_rate": 3.872217256203976e-05,
      "loss": 0.0003,
      "step": 5300
    },
    {
      "epoch": 0.6895671050951347,
      "grad_norm": 0.002897897269576788,
      "learning_rate": 3.8509343208615336e-05,
      "loss": 0.0342,
      "step": 5400
    },
    {
      "epoch": 0.7023368663006002,
      "grad_norm": 0.010157685726881027,
      "learning_rate": 3.829651385519091e-05,
      "loss": 0.0393,
      "step": 5500
    },
    {
      "epoch": 0.7151066275060657,
      "grad_norm": 0.024639446288347244,
      "learning_rate": 3.808368450176649e-05,
      "loss": 0.0472,
      "step": 5600
    },
    {
      "epoch": 0.727876388711531,
      "grad_norm": 0.0020470954477787018,
      "learning_rate": 3.787085514834206e-05,
      "loss": 0.0225,
      "step": 5700
    },
    {
      "epoch": 0.7406461499169965,
      "grad_norm": 0.003175919409841299,
      "learning_rate": 3.765802579491764e-05,
      "loss": 0.0336,
      "step": 5800
    },
    {
      "epoch": 0.753415911122462,
      "grad_norm": 0.00801642332226038,
      "learning_rate": 3.744519644149321e-05,
      "loss": 0.0876,
      "step": 5900
    },
    {
      "epoch": 0.7661856723279274,
      "grad_norm": 0.2831035852432251,
      "learning_rate": 3.723236708806879e-05,
      "loss": 0.0373,
      "step": 6000
    },
    {
      "epoch": 0.7789554335333929,
      "grad_norm": 0.0007073971792124212,
      "learning_rate": 3.701953773464437e-05,
      "loss": 0.0008,
      "step": 6100
    },
    {
      "epoch": 0.7917251947388584,
      "grad_norm": 0.01677067205309868,
      "learning_rate": 3.680670838121994e-05,
      "loss": 0.0204,
      "step": 6200
    },
    {
      "epoch": 0.8044949559443239,
      "grad_norm": 0.008558420464396477,
      "learning_rate": 3.659387902779551e-05,
      "loss": 0.0213,
      "step": 6300
    },
    {
      "epoch": 0.8172647171497893,
      "grad_norm": 0.010564401745796204,
      "learning_rate": 3.638104967437109e-05,
      "loss": 0.0761,
      "step": 6400
    },
    {
      "epoch": 0.8300344783552548,
      "grad_norm": 0.021022234112024307,
      "learning_rate": 3.6168220320946664e-05,
      "loss": 0.0378,
      "step": 6500
    },
    {
      "epoch": 0.8428042395607203,
      "grad_norm": 0.003616402158513665,
      "learning_rate": 3.595539096752224e-05,
      "loss": 0.0283,
      "step": 6600
    },
    {
      "epoch": 0.8555740007661857,
      "grad_norm": 0.005158107727766037,
      "learning_rate": 3.574256161409782e-05,
      "loss": 0.0185,
      "step": 6700
    },
    {
      "epoch": 0.8683437619716511,
      "grad_norm": 0.010169933550059795,
      "learning_rate": 3.5529732260673394e-05,
      "loss": 0.0454,
      "step": 6800
    },
    {
      "epoch": 0.8811135231771166,
      "grad_norm": 0.003029465675354004,
      "learning_rate": 3.531690290724897e-05,
      "loss": 0.0277,
      "step": 6900
    },
    {
      "epoch": 0.893883284382582,
      "grad_norm": 0.0015656830510124564,
      "learning_rate": 3.5104073553824545e-05,
      "loss": 0.0001,
      "step": 7000
    },
    {
      "epoch": 0.9066530455880475,
      "grad_norm": 0.006095689721405506,
      "learning_rate": 3.489124420040012e-05,
      "loss": 0.0245,
      "step": 7100
    },
    {
      "epoch": 0.919422806793513,
      "grad_norm": 0.0012182475766167045,
      "learning_rate": 3.4678414846975696e-05,
      "loss": 0.0337,
      "step": 7200
    },
    {
      "epoch": 0.9321925679989784,
      "grad_norm": 0.005973614286631346,
      "learning_rate": 3.4465585493551275e-05,
      "loss": 0.0341,
      "step": 7300
    },
    {
      "epoch": 0.9449623292044439,
      "grad_norm": 0.0061301300302147865,
      "learning_rate": 3.425275614012685e-05,
      "loss": 0.0648,
      "step": 7400
    },
    {
      "epoch": 0.9577320904099094,
      "grad_norm": 0.006170263513922691,
      "learning_rate": 3.4039926786702426e-05,
      "loss": 0.0229,
      "step": 7500
    },
    {
      "epoch": 0.9705018516153748,
      "grad_norm": 0.012168193235993385,
      "learning_rate": 3.3827097433278e-05,
      "loss": 0.0431,
      "step": 7600
    },
    {
      "epoch": 0.9832716128208403,
      "grad_norm": 0.0036535467952489853,
      "learning_rate": 3.361426807985357e-05,
      "loss": 0.0168,
      "step": 7700
    },
    {
      "epoch": 0.9960413740263057,
      "grad_norm": 0.003766321111470461,
      "learning_rate": 3.340143872642915e-05,
      "loss": 0.0271,
      "step": 7800
    },
    {
      "epoch": 1.0088111352317712,
      "grad_norm": 0.0014452228788286448,
      "learning_rate": 3.318860937300473e-05,
      "loss": 0.0182,
      "step": 7900
    },
    {
      "epoch": 1.0215808964372366,
      "grad_norm": 0.0019284215522930026,
      "learning_rate": 3.297578001958031e-05,
      "loss": 0.0001,
      "step": 8000
    },
    {
      "epoch": 1.0343506576427022,
      "grad_norm": 0.005170060787349939,
      "learning_rate": 3.276295066615588e-05,
      "loss": 0.0233,
      "step": 8100
    },
    {
      "epoch": 1.0471204188481675,
      "grad_norm": 0.001666469150222838,
      "learning_rate": 3.255012131273145e-05,
      "loss": 0.0226,
      "step": 8200
    },
    {
      "epoch": 1.059890180053633,
      "grad_norm": 0.0009114749846048653,
      "learning_rate": 3.233729195930703e-05,
      "loss": 0.0155,
      "step": 8300
    },
    {
      "epoch": 1.0726599412590985,
      "grad_norm": 0.0053224763832986355,
      "learning_rate": 3.21244626058826e-05,
      "loss": 0.0492,
      "step": 8400
    },
    {
      "epoch": 1.0854297024645638,
      "grad_norm": 0.002553157974034548,
      "learning_rate": 3.191163325245818e-05,
      "loss": 0.038,
      "step": 8500
    },
    {
      "epoch": 1.0981994636700294,
      "grad_norm": 0.0009521124302409589,
      "learning_rate": 3.169880389903376e-05,
      "loss": 0.007,
      "step": 8600
    },
    {
      "epoch": 1.1109692248754948,
      "grad_norm": 0.0010190693428739905,
      "learning_rate": 3.148597454560933e-05,
      "loss": 0.0174,
      "step": 8700
    },
    {
      "epoch": 1.1237389860809603,
      "grad_norm": 0.001328379032202065,
      "learning_rate": 3.1273145192184905e-05,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 1.1365087472864257,
      "grad_norm": 0.0005001717945560813,
      "learning_rate": 3.1060315838760484e-05,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 1.1492785084918913,
      "grad_norm": 0.001664903131313622,
      "learning_rate": 3.0847486485336056e-05,
      "loss": 0.0265,
      "step": 9000
    },
    {
      "epoch": 1.1620482696973566,
      "grad_norm": 0.0011353082954883575,
      "learning_rate": 3.0634657131911635e-05,
      "loss": 0.0141,
      "step": 9100
    },
    {
      "epoch": 1.1748180309028222,
      "grad_norm": 0.0010729475179687142,
      "learning_rate": 3.042182777848721e-05,
      "loss": 0.0267,
      "step": 9200
    },
    {
      "epoch": 1.1875877921082876,
      "grad_norm": 0.013246826827526093,
      "learning_rate": 3.0208998425062786e-05,
      "loss": 0.0732,
      "step": 9300
    },
    {
      "epoch": 1.200357553313753,
      "grad_norm": 0.0017484117997810245,
      "learning_rate": 2.9996169071638365e-05,
      "loss": 0.0002,
      "step": 9400
    },
    {
      "epoch": 1.2131273145192185,
      "grad_norm": 0.003073700238019228,
      "learning_rate": 2.9783339718213937e-05,
      "loss": 0.0254,
      "step": 9500
    },
    {
      "epoch": 1.2258970757246839,
      "grad_norm": 0.0011376546462997794,
      "learning_rate": 2.9570510364789513e-05,
      "loss": 0.0001,
      "step": 9600
    },
    {
      "epoch": 1.2386668369301495,
      "grad_norm": 0.0006592737627215683,
      "learning_rate": 2.935768101136509e-05,
      "loss": 0.0001,
      "step": 9700
    },
    {
      "epoch": 1.2514365981356148,
      "grad_norm": 0.0007244658772833645,
      "learning_rate": 2.9144851657940664e-05,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 1.2642063593410804,
      "grad_norm": 0.0035550741013139486,
      "learning_rate": 2.893202230451624e-05,
      "loss": 0.0527,
      "step": 9900
    },
    {
      "epoch": 1.2769761205465457,
      "grad_norm": 0.0007216320955194533,
      "learning_rate": 2.8719192951091818e-05,
      "loss": 0.0126,
      "step": 10000
    },
    {
      "epoch": 1.2897458817520113,
      "grad_norm": 0.0013838554732501507,
      "learning_rate": 2.850636359766739e-05,
      "loss": 0.0203,
      "step": 10100
    },
    {
      "epoch": 1.3025156429574767,
      "grad_norm": 0.000580290739890188,
      "learning_rate": 2.829353424424297e-05,
      "loss": 0.0059,
      "step": 10200
    },
    {
      "epoch": 1.315285404162942,
      "grad_norm": 0.0003478401340544224,
      "learning_rate": 2.8080704890818545e-05,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 1.3280551653684076,
      "grad_norm": 0.0006507755606435239,
      "learning_rate": 2.7867875537394117e-05,
      "loss": 0.0163,
      "step": 10400
    },
    {
      "epoch": 1.3408249265738732,
      "grad_norm": 0.0033585685305297375,
      "learning_rate": 2.7655046183969696e-05,
      "loss": 0.024,
      "step": 10500
    },
    {
      "epoch": 1.3535946877793386,
      "grad_norm": 0.001032522413879633,
      "learning_rate": 2.744221683054527e-05,
      "loss": 0.0001,
      "step": 10600
    },
    {
      "epoch": 1.366364448984804,
      "grad_norm": 0.0008899949607439339,
      "learning_rate": 2.7229387477120844e-05,
      "loss": 0.0334,
      "step": 10700
    },
    {
      "epoch": 1.3791342101902695,
      "grad_norm": 0.0011548580368980765,
      "learning_rate": 2.7016558123696422e-05,
      "loss": 0.021,
      "step": 10800
    },
    {
      "epoch": 1.3919039713957349,
      "grad_norm": 0.0018906421028077602,
      "learning_rate": 2.6803728770271998e-05,
      "loss": 0.0365,
      "step": 10900
    },
    {
      "epoch": 1.4046737326012004,
      "grad_norm": 0.0010231807827949524,
      "learning_rate": 2.6590899416847577e-05,
      "loss": 0.0214,
      "step": 11000
    },
    {
      "epoch": 1.4174434938066658,
      "grad_norm": 0.001599521841853857,
      "learning_rate": 2.637807006342315e-05,
      "loss": 0.0416,
      "step": 11100
    },
    {
      "epoch": 1.4302132550121311,
      "grad_norm": 0.0004918271442875266,
      "learning_rate": 2.616524070999872e-05,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 1.4429830162175967,
      "grad_norm": 0.0006513568223454058,
      "learning_rate": 2.5952411356574304e-05,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 1.4557527774230623,
      "grad_norm": 0.0004931526491418481,
      "learning_rate": 2.5739582003149876e-05,
      "loss": 0.0498,
      "step": 11400
    },
    {
      "epoch": 1.4685225386285277,
      "grad_norm": 0.0006083964253775775,
      "learning_rate": 2.5526752649725448e-05,
      "loss": 0.0149,
      "step": 11500
    },
    {
      "epoch": 1.481292299833993,
      "grad_norm": 0.0006419005221687257,
      "learning_rate": 2.531392329630103e-05,
      "loss": 0.0001,
      "step": 11600
    },
    {
      "epoch": 1.4940620610394586,
      "grad_norm": 0.00020152072829660028,
      "learning_rate": 2.5101093942876602e-05,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 1.5068318222449242,
      "grad_norm": 0.000291999225737527,
      "learning_rate": 2.4888264589452178e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 1.5196015834503895,
      "grad_norm": 0.0013569615548476577,
      "learning_rate": 2.4675435236027757e-05,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 1.532371344655855,
      "grad_norm": 0.00035663862945511937,
      "learning_rate": 2.446260588260333e-05,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 1.5451411058613203,
      "grad_norm": 0.0005399181973189116,
      "learning_rate": 2.4249776529178905e-05,
      "loss": 0.0075,
      "step": 12100
    },
    {
      "epoch": 1.5579108670667858,
      "grad_norm": 0.00040187634294852614,
      "learning_rate": 2.403694717575448e-05,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 1.5706806282722514,
      "grad_norm": 0.00026384711964055896,
      "learning_rate": 2.382411782233006e-05,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 1.5834503894777168,
      "grad_norm": 0.00011826057743746787,
      "learning_rate": 2.361128846890563e-05,
      "loss": 0.0009,
      "step": 12400
    },
    {
      "epoch": 1.5962201506831821,
      "grad_norm": 0.00012281330418772995,
      "learning_rate": 2.3398459115481207e-05,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 1.6089899118886477,
      "grad_norm": 0.011205011047422886,
      "learning_rate": 2.3185629762056786e-05,
      "loss": 0.0465,
      "step": 12600
    },
    {
      "epoch": 1.6217596730941133,
      "grad_norm": 0.006594792474061251,
      "learning_rate": 2.2972800408632358e-05,
      "loss": 0.0474,
      "step": 12700
    },
    {
      "epoch": 1.6345294342995786,
      "grad_norm": 0.003891974687576294,
      "learning_rate": 2.2759971055207933e-05,
      "loss": 0.0221,
      "step": 12800
    },
    {
      "epoch": 1.647299195505044,
      "grad_norm": 0.0009697846253402531,
      "learning_rate": 2.2547141701783512e-05,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 1.6600689567105094,
      "grad_norm": 0.002531249774619937,
      "learning_rate": 2.2334312348359088e-05,
      "loss": 0.0437,
      "step": 13000
    },
    {
      "epoch": 1.672838717915975,
      "grad_norm": 0.0008265050128102303,
      "learning_rate": 2.212148299493466e-05,
      "loss": 0.0001,
      "step": 13100
    },
    {
      "epoch": 1.6856084791214405,
      "grad_norm": 0.001810327172279358,
      "learning_rate": 2.190865364151024e-05,
      "loss": 0.0518,
      "step": 13200
    },
    {
      "epoch": 1.6983782403269059,
      "grad_norm": 0.0009013748494908214,
      "learning_rate": 2.1695824288085814e-05,
      "loss": 0.0001,
      "step": 13300
    },
    {
      "epoch": 1.7111480015323712,
      "grad_norm": 0.0003936740104109049,
      "learning_rate": 2.148299493466139e-05,
      "loss": 0.0076,
      "step": 13400
    },
    {
      "epoch": 1.7239177627378368,
      "grad_norm": 0.0006269809673540294,
      "learning_rate": 2.1270165581236966e-05,
      "loss": 0.0001,
      "step": 13500
    },
    {
      "epoch": 1.7366875239433024,
      "grad_norm": 0.0003240521182306111,
      "learning_rate": 2.105733622781254e-05,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 1.7494572851487677,
      "grad_norm": 0.00021340152306947857,
      "learning_rate": 2.0844506874388117e-05,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 1.762227046354233,
      "grad_norm": 0.00017972601926885545,
      "learning_rate": 2.0631677520963692e-05,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 1.7749968075596987,
      "grad_norm": 0.0001711039658403024,
      "learning_rate": 2.0418848167539268e-05,
      "loss": 0.0025,
      "step": 13900
    },
    {
      "epoch": 1.787766568765164,
      "grad_norm": 0.000281249318504706,
      "learning_rate": 2.0206018814114843e-05,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 1.8005363299706296,
      "grad_norm": 0.0005387265118770301,
      "learning_rate": 1.999318946069042e-05,
      "loss": 0.0255,
      "step": 14100
    },
    {
      "epoch": 1.813306091176095,
      "grad_norm": 0.00035607596510089934,
      "learning_rate": 1.9780360107265994e-05,
      "loss": 0.0,
      "step": 14200
    },
    {
      "epoch": 1.8260758523815603,
      "grad_norm": 0.001412498182617128,
      "learning_rate": 1.956753075384157e-05,
      "loss": 0.0318,
      "step": 14300
    },
    {
      "epoch": 1.838845613587026,
      "grad_norm": 0.000644627318251878,
      "learning_rate": 1.9354701400417145e-05,
      "loss": 0.0001,
      "step": 14400
    },
    {
      "epoch": 1.8516153747924915,
      "grad_norm": 92.42887115478516,
      "learning_rate": 1.9141872046992724e-05,
      "loss": 0.0237,
      "step": 14500
    },
    {
      "epoch": 1.8643851359979569,
      "grad_norm": 0.00046336461673490703,
      "learning_rate": 1.8929042693568297e-05,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 1.8771548972034222,
      "grad_norm": 0.0002604190376587212,
      "learning_rate": 1.8716213340143872e-05,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 1.8899246584088878,
      "grad_norm": 0.00027549589867703617,
      "learning_rate": 1.850338398671945e-05,
      "loss": 0.0074,
      "step": 14800
    },
    {
      "epoch": 1.9026944196143534,
      "grad_norm": 0.00045486149610951543,
      "learning_rate": 1.8290554633295027e-05,
      "loss": 0.0331,
      "step": 14900
    },
    {
      "epoch": 1.9154641808198187,
      "grad_norm": 0.00015844267909415066,
      "learning_rate": 1.80777252798706e-05,
      "loss": 0.0002,
      "step": 15000
    },
    {
      "epoch": 1.928233942025284,
      "grad_norm": 0.0005407367134466767,
      "learning_rate": 1.7864895926446178e-05,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 1.9410037032307494,
      "grad_norm": 0.0004972257884219289,
      "learning_rate": 1.7652066573021753e-05,
      "loss": 0.0178,
      "step": 15200
    },
    {
      "epoch": 1.953773464436215,
      "grad_norm": 0.00030555480043403804,
      "learning_rate": 1.7439237219597325e-05,
      "loss": 0.0171,
      "step": 15300
    },
    {
      "epoch": 1.9665432256416806,
      "grad_norm": 0.0006085188360884786,
      "learning_rate": 1.7226407866172904e-05,
      "loss": 0.0001,
      "step": 15400
    },
    {
      "epoch": 1.979312986847146,
      "grad_norm": 0.00024195633886847645,
      "learning_rate": 1.701357851274848e-05,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 1.9920827480526113,
      "grad_norm": 0.0003086718497797847,
      "learning_rate": 1.6800749159324055e-05,
      "loss": 0.0157,
      "step": 15600
    },
    {
      "epoch": 2.0048525092580767,
      "grad_norm": 0.00022387204808183014,
      "learning_rate": 1.658791980589963e-05,
      "loss": 0.0,
      "step": 15700
    },
    {
      "epoch": 2.0176222704635425,
      "grad_norm": 0.0002143560122931376,
      "learning_rate": 1.6375090452475206e-05,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 2.030392031669008,
      "grad_norm": 0.0001663559814915061,
      "learning_rate": 1.6162261099050782e-05,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 2.043161792874473,
      "grad_norm": 0.00013918410695623606,
      "learning_rate": 1.5949431745626358e-05,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 2.0559315540799386,
      "grad_norm": 9.402061550645158e-05,
      "learning_rate": 1.5736602392201933e-05,
      "loss": 0.0,
      "step": 16100
    },
    {
      "epoch": 2.0687013152854044,
      "grad_norm": 0.00027325915289111435,
      "learning_rate": 1.552377303877751e-05,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 2.0814710764908697,
      "grad_norm": 4.672029899666086e-05,
      "learning_rate": 1.5310943685353084e-05,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 2.094240837696335,
      "grad_norm": 9.849701746134087e-05,
      "learning_rate": 1.5098114331928661e-05,
      "loss": 0.0,
      "step": 16400
    },
    {
      "epoch": 2.1070105989018004,
      "grad_norm": 4.204858487355523e-05,
      "learning_rate": 1.4885284978504235e-05,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 2.119780360107266,
      "grad_norm": 8.106903987936676e-05,
      "learning_rate": 1.4672455625079813e-05,
      "loss": 0.0,
      "step": 16600
    },
    {
      "epoch": 2.1325501213127316,
      "grad_norm": 0.00026486426941119134,
      "learning_rate": 1.4459626271655388e-05,
      "loss": 0.0,
      "step": 16700
    },
    {
      "epoch": 2.145319882518197,
      "grad_norm": 4.937884659739211e-05,
      "learning_rate": 1.4246796918230962e-05,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 2.1580896437236623,
      "grad_norm": 5.277309537632391e-05,
      "learning_rate": 1.4033967564806537e-05,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 2.1708594049291277,
      "grad_norm": 0.00017186311015393585,
      "learning_rate": 1.3821138211382115e-05,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 2.1836291661345935,
      "grad_norm": 3.090687459916808e-05,
      "learning_rate": 1.3608308857957692e-05,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 2.196398927340059,
      "grad_norm": 2.9394046578090638e-05,
      "learning_rate": 1.3395479504533264e-05,
      "loss": 0.0,
      "step": 17200
    },
    {
      "epoch": 2.209168688545524,
      "grad_norm": 4.6263787226052955e-05,
      "learning_rate": 1.3182650151108841e-05,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 2.2219384497509895,
      "grad_norm": 5.349644925445318e-05,
      "learning_rate": 1.2969820797684417e-05,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 2.2347082109564553,
      "grad_norm": 6.557785673066974e-05,
      "learning_rate": 1.2756991444259994e-05,
      "loss": 0.0185,
      "step": 17500
    },
    {
      "epoch": 2.2474779721619207,
      "grad_norm": 0.0004197533708065748,
      "learning_rate": 1.2544162090835568e-05,
      "loss": 0.0153,
      "step": 17600
    },
    {
      "epoch": 2.260247733367386,
      "grad_norm": 6.989633402554318e-05,
      "learning_rate": 1.2331332737411143e-05,
      "loss": 0.0001,
      "step": 17700
    },
    {
      "epoch": 2.2730174945728514,
      "grad_norm": 8.574827370466664e-05,
      "learning_rate": 1.211850338398672e-05,
      "loss": 0.0099,
      "step": 17800
    },
    {
      "epoch": 2.2857872557783168,
      "grad_norm": 0.00010535425099078566,
      "learning_rate": 1.1905674030562296e-05,
      "loss": 0.0001,
      "step": 17900
    },
    {
      "epoch": 2.2985570169837826,
      "grad_norm": 3.329891842440702e-05,
      "learning_rate": 1.169284467713787e-05,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 2.311326778189248,
      "grad_norm": 4.089335197932087e-05,
      "learning_rate": 1.1480015323713447e-05,
      "loss": 0.0,
      "step": 18100
    },
    {
      "epoch": 2.3240965393947133,
      "grad_norm": 3.596959140850231e-05,
      "learning_rate": 1.1267185970289023e-05,
      "loss": 0.0,
      "step": 18200
    },
    {
      "epoch": 2.3368663006001786,
      "grad_norm": 6.51119407848455e-05,
      "learning_rate": 1.1054356616864598e-05,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 2.3496360618056444,
      "grad_norm": 0.00016747391782701015,
      "learning_rate": 1.0841527263440174e-05,
      "loss": 0.0002,
      "step": 18400
    },
    {
      "epoch": 2.36240582301111,
      "grad_norm": 4.669413829105906e-05,
      "learning_rate": 1.062869791001575e-05,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 2.375175584216575,
      "grad_norm": 4.8544268793193623e-05,
      "learning_rate": 1.0415868556591325e-05,
      "loss": 0.0,
      "step": 18600
    },
    {
      "epoch": 2.3879453454220405,
      "grad_norm": 0.0008581033907830715,
      "learning_rate": 1.0203039203166902e-05,
      "loss": 0.0404,
      "step": 18700
    },
    {
      "epoch": 2.400715106627506,
      "grad_norm": 5.03136106999591e-05,
      "learning_rate": 9.990209849742476e-06,
      "loss": 0.0,
      "step": 18800
    },
    {
      "epoch": 2.4134848678329717,
      "grad_norm": 7.74958316469565e-05,
      "learning_rate": 9.777380496318053e-06,
      "loss": 0.0,
      "step": 18900
    },
    {
      "epoch": 2.426254629038437,
      "grad_norm": 8.07119213277474e-05,
      "learning_rate": 9.564551142893629e-06,
      "loss": 0.0,
      "step": 19000
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 3.50127556885127e-05,
      "learning_rate": 9.351721789469205e-06,
      "loss": 0.0,
      "step": 19100
    },
    {
      "epoch": 2.4517941514493677,
      "grad_norm": 3.397934779059142e-05,
      "learning_rate": 9.13889243604478e-06,
      "loss": 0.0,
      "step": 19200
    },
    {
      "epoch": 2.4645639126548335,
      "grad_norm": 3.515793650876731e-05,
      "learning_rate": 8.926063082620356e-06,
      "loss": 0.0001,
      "step": 19300
    },
    {
      "epoch": 2.477333673860299,
      "grad_norm": 3.207786721759476e-05,
      "learning_rate": 8.713233729195931e-06,
      "loss": 0.0163,
      "step": 19400
    },
    {
      "epoch": 2.4901034350657643,
      "grad_norm": 1.9878507373505272e-05,
      "learning_rate": 8.500404375771507e-06,
      "loss": 0.0003,
      "step": 19500
    },
    {
      "epoch": 2.5028731962712296,
      "grad_norm": 4.876725870417431e-05,
      "learning_rate": 8.287575022347082e-06,
      "loss": 0.0,
      "step": 19600
    },
    {
      "epoch": 2.515642957476695,
      "grad_norm": 2.8036432922817767e-05,
      "learning_rate": 8.074745668922658e-06,
      "loss": 0.0,
      "step": 19700
    },
    {
      "epoch": 2.5284127186821608,
      "grad_norm": 1.6873253116500564e-05,
      "learning_rate": 7.861916315498235e-06,
      "loss": 0.0,
      "step": 19800
    },
    {
      "epoch": 2.541182479887626,
      "grad_norm": 3.9668026147410274e-05,
      "learning_rate": 7.649086962073809e-06,
      "loss": 0.0,
      "step": 19900
    },
    {
      "epoch": 2.5539522410930915,
      "grad_norm": 0.051698971539735794,
      "learning_rate": 7.436257608649386e-06,
      "loss": 0.0102,
      "step": 20000
    },
    {
      "epoch": 2.5667220022985573,
      "grad_norm": 3.079825182794593e-05,
      "learning_rate": 7.223428255224961e-06,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 2.5794917635040227,
      "grad_norm": 4.915449608233757e-05,
      "learning_rate": 7.010598901800537e-06,
      "loss": 0.0,
      "step": 20200
    },
    {
      "epoch": 2.592261524709488,
      "grad_norm": 5.418766522780061e-05,
      "learning_rate": 6.797769548376112e-06,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 2.6050312859149534,
      "grad_norm": 1.3159762602299452e-05,
      "learning_rate": 6.584940194951688e-06,
      "loss": 0.0,
      "step": 20400
    },
    {
      "epoch": 2.6178010471204187,
      "grad_norm": 1.4524419384542853e-05,
      "learning_rate": 6.372110841527264e-06,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 2.630570808325884,
      "grad_norm": 2.458056405885145e-05,
      "learning_rate": 6.159281488102839e-06,
      "loss": 0.0,
      "step": 20600
    },
    {
      "epoch": 2.64334056953135,
      "grad_norm": 2.386438791290857e-05,
      "learning_rate": 5.946452134678415e-06,
      "loss": 0.0,
      "step": 20700
    },
    {
      "epoch": 2.6561103307368152,
      "grad_norm": 1.3375070011534262e-05,
      "learning_rate": 5.733622781253991e-06,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 2.6688800919422806,
      "grad_norm": 1.8818955140886828e-05,
      "learning_rate": 5.520793427829567e-06,
      "loss": 0.0099,
      "step": 20900
    },
    {
      "epoch": 2.6816498531477464,
      "grad_norm": 6.944821507204324e-05,
      "learning_rate": 5.307964074405142e-06,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 2.6944196143532118,
      "grad_norm": 3.416427716729231e-05,
      "learning_rate": 5.095134720980718e-06,
      "loss": 0.0,
      "step": 21100
    },
    {
      "epoch": 2.707189375558677,
      "grad_norm": 1.432639874110464e-05,
      "learning_rate": 4.8823053675562935e-06,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 2.7199591367641425,
      "grad_norm": 1.9780060029006563e-05,
      "learning_rate": 4.669476014131869e-06,
      "loss": 0.0,
      "step": 21300
    },
    {
      "epoch": 2.732728897969608,
      "grad_norm": 1.8759068552753888e-05,
      "learning_rate": 4.4566466607074446e-06,
      "loss": 0.0,
      "step": 21400
    },
    {
      "epoch": 2.745498659175073,
      "grad_norm": 2.070879054372199e-05,
      "learning_rate": 4.24381730728302e-06,
      "loss": 0.0001,
      "step": 21500
    },
    {
      "epoch": 2.758268420380539,
      "grad_norm": 1.629836879146751e-05,
      "learning_rate": 4.0309879538585965e-06,
      "loss": 0.0,
      "step": 21600
    },
    {
      "epoch": 2.7710381815860043,
      "grad_norm": 1.1551648640306666e-05,
      "learning_rate": 3.818158600434172e-06,
      "loss": 0.0051,
      "step": 21700
    },
    {
      "epoch": 2.7838079427914697,
      "grad_norm": 1.0743282473413274e-05,
      "learning_rate": 3.6053292470097476e-06,
      "loss": 0.0,
      "step": 21800
    },
    {
      "epoch": 2.7965777039969355,
      "grad_norm": 1.0563373507466167e-05,
      "learning_rate": 3.3924998935853235e-06,
      "loss": 0.0,
      "step": 21900
    },
    {
      "epoch": 2.809347465202401,
      "grad_norm": 1.7435926565667614e-05,
      "learning_rate": 3.179670540160899e-06,
      "loss": 0.0,
      "step": 22000
    }
  ],
  "logging_steps": 100,
  "max_steps": 23493,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5828433073465344.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
